## 计算图和反向传播

ref: http://www.cs.columbia.edu/~mcollins/ff2.pdf

### 计算图

用一序列计算步骤的有向图，用来表示模型

vertex节点是计算步骤，有向边edges表示输入的方向

优势： 1. 简单的函数进行组合可以表示复杂的模型；2. 可以自动微分。

定义1: 
$$
\lang n,l,E,u^1...u^n,d^1...d^n,f^{l+1}...f^n \rang
\\
$$
where:

- $n$ is an integer specifying the number of vertices in the graph.

- $l$ is an integer such that $1\le l <n$ that specifies the number of leaves（输入节点） in the graph.

- $E$ is a set of directed edges in the graph. Each edge is an ordered pair  $(j, i)$ where $j ∈ {1 . . . (n − 1)}, i ∈ {(l + 1) . . . n},$ and $j < i$.
- Each $u^i$ for $i = 1...n$ is a **variable** associated with vertex $i$ in the graph. $u^i$ is a variable in $\mathbb{R}^{d^i}$, hence $d^i$ for $i = 1...n$ is an integer specifying the dimensionality of the variable associated with variable $i$.
- We take $u^n$ to be the **output variable**（输出节点） in the graph. Often we have $d^n = 1$, so that the output variable is a scalar; however we will consider the general case where $d^n$ is any integer greater than $0$.
- Each $f^i$ for $i = (l + 1)...n$ is a **local function** associated with vertex $i$ in the graph. If we define $\alpha^i=\lang u^j|(j,i)\in E \rang$ hence $α^i$ （输入向量的和）is a vector formed by concatenating the vectors $u^j$ such that $(j, i) \in E$ and in addition we define $ \bar{d^i}=\sum\limits_{j:(j,i)\in E} d^j$ （输入维度的加和）then we have dimensions $\alpha^i \in \mathbb{R}^{\bar{d^i}}, f^i:\mathbb{R}^{\bar{d^i}}\rarr \mathbb{R}^{d^i}, and f^i(a^i) \in \mathbb{d^i}$.

举个例子

**Example 1**
$$
\begin{matrix} u^3 & \rarr & u^4
\\ 
\uarr & \nwarrow & \uarr 
\\ u^1 &  & u^2 
\end{matrix}
\tag{figure 1}
\\
n=4, l=2, E=\{(1,3),(2,3),(2,4),(3,4)\}
\\
d^i = 1 \quad for i = 1...4
\\
f^3(u^1,u^2) = u^1+u^2
\\
f^4(u^2,u^3) = u2\times u^3
$$



#### Forward Algorithm 前向

对于除了输入节点的$u^i \quad for \;i=(l+1)...n$，节点上的变量是这么计算的
$$
u^i = f^i(\alpha^i)
\\
where \quad \alpha^i=\lang u^j|(j,i)\in E \rang
$$
应为计算图上的节点满足拓扑排序，$u^j$肯定在$u^i$之前都计算过了。

向example 1中带入数据进行计算
$$
u^1 = 2, u^2=3
\\
f^3(u^1,u^2) = u^1+u^2=5
\\
f^4(u^2,u^3) = u2\times u^3=15
\\
Output = u^4 = 15
$$
定义2： **全局公式**
$$
If\quad i\in{1...l}
\\
h^i(u^1...u^l)=u^i
\\
else\; if\quad i\in\{(l+1)...n\}
\\
u^i = f^i(\alpha^i)
\\
where \quad \alpha^i=\lang h^j(u^1...u^l)|(j,i)\in E \rang
$$
这后面的$h^j(u^1...u^l)$是要递归的计算的（多层嵌套）

#### 以简单的前馈网络为例子作计算图推导

模型结构（包含一个hidden layer）
$$
\begin{matrix}
x^i &          &   &       & V       &           &   &       & y^i &           \\
    & \searrow &   &       &         & \searrow  &   &       &     & \searrow  \\
W   & \rarr    & z & \rarr & h       & \rarr     & l & \rarr & q   & \rarr & o \\
    & \nearrow &   &       &         & \nearrow  &   &       &     &           \\
b   &          &   &       & \gamma  &           &   &       &     &   
\end{matrix}
\tag{figure 2}
$$
$$
\begin{align*}
& vars. \; n=11 \\ 
& leaf \; vars \; l=6 \\
& leaf \; vars. \;: \\
& u^1=W\in\mathbb{R}^{m\times d} \\
& u^2=b\in\mathbb{R}^m \\
& u^3=x^i\in\mathbb{R}^d \\
& u^4=y^i\in\{1...K\} \\
& u^5=V\in\mathbb{R}^{K\times m} \\
& u^6=\gamma\in\mathbb{R}^K \\
& Non-leaf \;vars. \;: \\
& u^7=z\in\mathbb{R}^m = Wx^i+b \\
& u^8=h\in\mathbb{R}^m=g(z) \\
& u^9=l\in\mathbb{R}^K=Vh+\gamma \\
& u^{10}=q\in\mathbb{R}^K=LOG-SOFTMAX(l) \\
& u^{11}=o\in\mathbb{R}=-q_{y^i} \quad use \; y^i \; lable\; as\; index\; to\; lookup\; corresponding\; q^i \; just\; plain\; CrossEntropy  \\
\end{align*}
$$



网络定义的模型公式为

$p(y^i|x^i;V,\gamma,W,b)=\frac{exp\{V_{y^i}\cdot g(Wx^i+b)+\gamma_{y^i}\}}{\sum_{y^{'}} exp\{V_{y^{'}}\cdot g(Wx^i+b)+\gamma_{y^{'}}\}}$

输入 $x^i\in \mathbb{R}^d$ 

标签 $y^i\in\{1...K\}$

网络中有$m$个神经元，则有 $W\in\mathbb{R}^{m\times d} \quad and \quad b\in\mathbb{R}^m$

激活函数 $g:\mathbb{R}^m \rarr \mathbb{R}^m$

对于每一个 $y^i$ 而言都有 $V_y \in \mathbb{R}^m, \gamma_y$ 是对应的biase，K个标签的叠加结果即 $V\in\mathbb{R}^{K\times m}, \gamma\in\mathbb{R}^K$

定义方程  $L(x^i,y^i,W,b,V,\gamma)=-log(p(y^i|x^i;V,\gamma,W,b))$

这个$p(y^i|x^i;V,\gamma,W,b)$就是softmax后的概率

#### 讨论一下偏导数的计算和链式法则

1. 标量对标量的偏导

   对于给定函数 $f:\mathbb{R}^n\rarr\mathbb{R}$，等式 $y=f(z^1,z^2,...,z^n), y\in\mathbb{R}\;and\;z^i\in\mathbb{R}$ 则对于变量$z^i$的偏导数为：$\frac{\partial f(z^1...z^n)}{\partial z^i}=\lim\limits_{h\rarr0}\frac{f(z^1...,z^i+h,...z^n)-f(z^1...z^n)}{h}$ 也可以写成$\frac{\partial y}{\partial z^i}|^f_{z^1...z^n}$

2. 假设有$y=f(z^1,z^2,...,z^n), z^i=g^i(x^1...x^{n^{'}}), y, z^i \;and\; x^i\; is\; scalar$，定义全局函数h为$h(x^1...x^{n^{'}})=f(g^1(x^1...x^{n^{'}}),g^2(x^1...x^{n^{'}}),...,g^n(x^1...x^{n^{'}}))$， h求对x的偏导，$\frac{\partial h(x^1...x^{n^{'}})}{\partial x^i}=\frac{\partial y}{\partial x^i}|^h_{x^1...x^{n^{'}}}$，链式求导又可以得到，$\frac{\partial y}{\partial x^i}=\sum\limits^n_{j=1}\frac{\partial y}{\partial z^j}\times \frac{\partial z^j}{\partial x^i}$ 更细节的表示 $\frac{\partial y}{\partial x^i}|^h_{x^1...x^{n^{'}}}=\sum^{n}_{j=1}\frac{\partial y}{\partial z^j}|^f_{z^1...z^n}\times \frac{\partial z^j}{\partial x^i}|^{g^j}_{x^1...x^{n^{'}}}$

3. 拓展标量到向量，$z^i\in \mathbb{R}^{d^i},y\in \mathbb{R}^m, \; y=f(z^1,z^2,...,z^n)$依据向量对向量的求导法则$k\in \{1...m\},\;k^{'}\in \{1...d^i\} \; \Big[\frac{\partial f(z^1...z^n)}{\partial z^i}\Big]_{k,k^{'}}=\Big[\frac{\partial y}{\partial z^i}|^f_{z^1...z^n}\Big]_{k,k^{'}}=\frac{\partial y_k}{\partial z^i_{k^{'}}}|^{f_k}_{z^1...z^n}$

   举个例子$\frac{\partial y}{\partial z^1} = \left[ \begin{matrix} \frac{\partial y_1}{\partial z^1_{1}}|^{f_1}_{z^1} & \dots & \frac{\partial y_1}{\partial z^1_{k^{'}}}|^{f_1}_{z^1}\\ \vdots & \ddots & \vdots \\ \frac{\partial y_m}{\partial z^1_{1}}|^{f_m}_{z^1} & \dots & \frac{\partial y_m}{\partial z^1_{k^{'}}}|^{f_m}_{z^1} \end{matrix}\right]$这里的下标y和下标z都是标量了

4. 针对向量对向量的链式法则 $y=f(z^1,z^2,...,z^n), z^i=g^i(x^1...x^{n^{'}}), y, z^i \;and\; x^i\; is\; vector$链式求导法则有$\frac{\partial y}{\underbrace{\partial x^i}_{d(y)\times d(x^i)}}=\sum\limits^n_{j=1}\frac{\partial y}{\underbrace{\partial z^j}_{d(y)\times d(z^j)}}\times \frac{\partial z^j}{\underbrace{\partial x^i}_{d(z^j)\times d(x^i)}}$

   或则$\underbrace{\frac{\partial y}{\partial x^i}|^h_{x^1...x^{n^{'}}}}_{d(y)\times d(x^i)}=\sum^{n}_{j=1}\underbrace{\frac{\partial y}{\partial z^j}|^f_{z^1...z^n}}_{d(y)\times d(z^j)}\times \underbrace{\frac{\partial z^j}{\partial x^i}|^{g^j}_{x^1...x^{n^{'}}}}_{d(z^j)\times d(x^i)}$ 对于$output\;y_k \;and\; input\; x^j_{k^{'}}$可以推出$\frac{\partial y_k}{\partial x^j_{k^{'}}}=\sum\limits^{n}_{i=1}\sum\limits^{d(z^i)}_{l=1}\frac{\partial y_k}{\partial z^i_l} \times \frac{\partial z^i_l}{\partial x^j_{k^{'}}}$

#### Backpropagation Algorithm 反向传播

回到计算图，假设有叶节点$u^1...u^l$输出根节点是$u^n$计算图的全局定义如下：
$$
u^n=h^n(u^1...u^l)\;, h^n\; global function
\\对于每个叶节点都可以计算Jacobian
\\ \underbrace{\frac{\partial u^n}{\partial u^i}|^{h^n}_{u^1...u^l}}_{d(u^n)\times d(u^i)}
\\ 拆分到标量就是
\\ \frac{\partial u^n_k}{\partial u^i_{k^{'}}} \quad k\in\{1...d(u^n)\}, k^{'}\in \{1...d(u^i)\}
\\ 对于figure2中的网络定义： o=-logp(y^i|x^i;V,\gamma,W,b)
\\叶节点包括y^i,x^i,V,\gamma,W,b
\\ 全局Jacobia可定义为
\\ \underbrace{\frac{\partial o}{\partial W}}_{1\times(m\times d)}, \underbrace{\frac{\partial o}{\partial b}}_{1\times(m)}, \underbrace{\frac{\partial o}{\partial V}}_{1\times(K\times m)}, \underbrace{\frac{\partial o}{\partial \gamma}}_{1\times(K)}
$$

#### Local Jacobians

计算图的非子节点有：
$$
u^i=f^i(\alpha ^i), i \in \{(l+1)...n\}
\\这个f^i就是有关节点i的局部Jacobians, \;同时有\alpha^i=\langle u^j|(j,i)\in E\rangle
$$
**Local Jacobain Functions**
$$
\forall (j,i)\in E, \; define\; local\; Jacobian \; 
\\J^{j\rarr i}(\alpha^i)=\frac{\partial f^i(\alpha^i)}{\partial u^j}=\frac{\partial u^i}{\partial u^j}|^{f^i}_{\alpha^i}
$$
看一下细节$\alpha^i=\langle u^j|(j,i)\in E\rangle$则有$\alpha^i \in \mathbb{R}^{\bar{d^i}}\; \alpha^i是与u^i节点相连的所有前序前序u^j的凭借，所以\bar{d^i}=\sum_{j:(j,i)\in E}d^j$，所以局部J是这样的一种映射$J^{j\rarr i}: \mathbb{R}^{\bar{d^i}} \rarr \mathbb{R}^{d^i\times d^j}$

**这里我们先假定**$J^{j\rarr i}(\alpha^i)$在$\alpha^i$上有定义，可微

**Forwards** 举例
$$
\begin{matrix} u^3 & \rarr & u^4
\\ 
\uarr & \nwarrow & \uarr 
\\ u^1 &  & u^2 
\end{matrix}
\\f^3(u^1,u^2) = u^1+u^2
\\f^4(u^2,u^3) = u^2\times u^3
\\则有:
\\J^{1\rarr 3}(u^1,u^2)=\frac{\partial u^3}{\partial u^1}|^{f^3}_{u^1,u^2}=1
\\J^{2\rarr 3}(u^1,u^2)=\frac{\partial u^3}{\partial u^2}|^{f^3}_{u^1,u^2}=1
\\J^{2\rarr 4}(u^2,u^3)=\frac{\partial u^4}{\partial u^2}|^{f^4}_{u^2,u^3}=u^3
\\J^{3\rarr 4}(u^2,u^3)=\frac{\partial u^4}{\partial u^3}|^{f^4}_{u^2,u^3}=u^2
\\假设 u^1=2 \quad u^2=3
\\ forward: u^3=f^3(u^1,u^2)=u^1+u^2=5, u^4=f^4(u^2,u^3)=u^2\times u^3=15
\\局部J：
\\J^{1\rarr 3}(u^1,u^2)=1
\\J^{2\rarr 3}(u^1,u^2)=1
\\J^{2\rarr 4}(u^2,u^3)=u^3=5
\\J^{3\rarr 4}(u^2,u^3)=u^2=3
$$

#### BP

全局Jacobians
$$
\frac{\partial u^n}{\partial u^i}|^{h^n}_{u^1...u^l}
$$
when we want to run backwards of the graph, first initialize an Identity matrix $P^n=I(d^n)$,then BP run backworks of the graph for j=(n-1),....1
$$
P^j=\sum\limits_{i:(j,i)\in E}P^iJ^{j\rarr i}(\alpha^i)
$$
need to go backwards to leaf vertex $j=1,...l$
$$
P^j=\frac{\partial u^n}{u^j}|h^n_{u^1...u^l}
$$
back to case 
$$
\begin{matrix} u^3 & \rarr & u^4 \\ \uarr & \nwarrow & \uarr \\ u^1 &  & u^2 \end{matrix} \quad n=4, l=2, E=\{(1,3),(2,3),(3,4),(2,4)\}\; and \; all\; d^i=1
\\local\; function:
\\f^3(u^1,u^2)=u^1+u^2
\\f^4(u^2,u^3)=u^2\times u^3
\\ local \; Jacobians:
\\J^{1\rarr 3}(u^1,u^2)=1
\\J^{2\rarr 3}(u^1,u^2)=1
\\J^{2\rarr 4}(u^2,u^3)=u^3
\\J^{3\rarr 4}(u^2,u^3)=u^2
\\if:
\\ u^1=2 \quad u^2=3
\\ forward: 
\\ u^3=u^1+u^2=5, \\ u^4=u^2\times u^3=15
\\The backward pass then:
\\ P^4 = 1\quad (initializing)
\\ P^3 = P^4 \times J^{3\rarr 4}(u^2,u^3)= 1\times u^2=3
\\ P^2 = P^3J^{2\rarr 3}(u^1,u^2) + P^4J^{2\rarr 4}(u^2,u^3)=3\times 1 + 1\times 5 = 8
\\ P^1 = P^3J^{1\rarr 3}(u^1,u^2)=3\times 1=3
\\Output:
\\ \frac{\partial u^4}{\partial u^1}|^{h^n}_{u^1...u^2}=P^1=3
\\ \frac{\partial u^4}{\partial u^2}|^{h^n}_{u^1...u^2}=P^2=8
\\ Global \; function:
\\ h^4(u^1,u^2)=u^2\times (u^1+u^2)
$$
**证明过程**

$Def \; \rho(j,i)$ 是节点j到i之间的有向路径，j到i的这条通路上有向路径$p=(v_1,v_2), ...,(v_{n-1},v_n) where \; v_1=j, v_n=i, n \ge 2$
$$
Def: Directed\; Paths上Jacobians的积
\\ \prod\limits_{(a,b)\in p} = J^{a\rarr b}(\alpha^b)=J^{v_{n-1}\rarr v_n}(\alpha^{v_n})\times J^{v_{n-2}\rarr v_{n-1}}(\alpha^{v_{n-1}})...\times J^{v_{1}\rarr v_2}(\alpha^{v_2})
$$

**定理1**
$$
有\lang n,l,E,u^1...u^n,d^1...d^n,f^{l+1}...f^n \rang
\\ leaf\; vars.: u^1,...,u^l\quad non-leaf\; vars: u^{l+1},...,u^n
\\ \quad
\\ \forall (j,i)\in E, \; define\; local\; Jacobian \; 
\\J^{j\rarr i}(\alpha^i)=\frac{\partial f^i(\alpha^i)}{\partial u^j}=\frac{\partial u^i}{\partial u^j}|^{f^i}_{\alpha^i}
\\ \quad
\\ for\; \forall j\in\{1,...,l\}, \forall i\in\{l+1,...,n\}
\\ \frac{\partial u^i}{\partial u^j}|^{h^i}_{u^1...u^l} = \sum\limits_{p\in \rho(j,i)}\prod\limits_{(a,b)\in p} = J^{a\rarr b}(\alpha^b)
$$
**定理2**
$$
For \; j = (n-1), ... ,1 
\\ P^j = \sum\limits_{p\in \rho(j,n)}\prod\limits_{(a,b)\in p} = J^{a\rarr b}(\alpha^b)
\\ for \; j=1,...,l可推出定理1的一个特例
\\ P^j = \frac{\partial u^n}{\partial u^j}|^{h^n}_{u^1...u^l}
\\ P^j = \sum\limits_{p\in \rho(j,n)}\prod\limits_{(a,b)\in p} = J^{a\rarr b}(\alpha^b)
$$
**扩展** 当局部Jacobians不能定义时怎么办

当假定局部Jacobians是有定义的时候，也就是局部函数是有定义可求导的
$$
\\J^{j\rarr i}(\alpha^i)=\frac{\partial f^i(\alpha^i)}{\partial u^j}=\frac{\partial u^i}{\partial u^j}|^{f^i}_{\alpha^i}
$$
但是如果偏导未定义不能求导怎么办？

比如上边：
$$
u^{11}=o\in\mathbb{R}=-q_{y^i} \quad use \; y^i \; lable\; as\; index\; to\; lookup\; corresponding\; q^i \; just\; plain\; CrossEntropy
\\ equals
\\
u^{11}=-u^{10}_{u^4}
$$
这里o的结果等于要根据$u^4$的值直接进行选择。$u^4=y^i \in \{1,2,...,K\}$因为是离散的所以$\frac{\partial u^{11}}{\partial u^4}|^{f^{11}}_{\alpha^{11}}$其实不能求导。



